{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate change tweet classsification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed at classifying if a person/custumer believe in climate change or not, this is to help companies with determining if customising their product for lessining carbon footprint and environmental impact, is a good idea or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/phaks323/ea6/eee7854f4e98462b97fce4be0466a2fe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(api_key='jOPX4ya8LjBTfsqRhitiRrIUo', project_name=\"ea6\", workspace=\"phaks323\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing packages that will be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# set plot style\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the fields of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test_with_no_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting an idea of the data on hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data types contained on our data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15819 entries, 0 to 15818\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  15819 non-null  int64 \n",
      " 1   message    15819 non-null  object\n",
      " 2   tweetid    15819 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 370.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if we have null/ empty fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "message      0\n",
       "tweetid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the numberof time each sentiment appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    3640\n",
       " 0    2353\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural language processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a function which will clean our text or tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief not think carbon dioxid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "      <td>not like we lack evidence anthropogenic global...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "      <td>researcher say we three year act climate chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "      <td>todayinmaker wired  wa pivotal year in war cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "      <td>and racist sexist climate change denying bigo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Worth a read whether you do or don't believe i...</td>\n",
       "      <td>425577</td>\n",
       "      <td>worth read whether you not believe in climate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @thenation: Mike Pence doesn’t believe in g...</td>\n",
       "      <td>294933</td>\n",
       "      <td>mike penny doesn’t believe in global warming s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @makeandmendlife: Six big things we can ALL...</td>\n",
       "      <td>992717</td>\n",
       "      <td>six big thing we can today fight climate chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>@AceofSpadesHQ My 8yo nephew is inconsolable. ...</td>\n",
       "      <td>664510</td>\n",
       "      <td>my yo nephew inconsolable want die old age lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @paigetweedy: no offense… but like… how do ...</td>\n",
       "      <td>260471</td>\n",
       "      <td>no offense… but like… how you just not believe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @StephenSchlegel: she's thinking about how ...</td>\n",
       "      <td>295793</td>\n",
       "      <td>shes thinking about how shes going die because...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            message  tweetid  \\\n",
       "0           1  PolySciMajor EPA chief doesn't think carbon di...   625221   \n",
       "1           1  It's not like we lack evidence of anthropogeni...   126103   \n",
       "2           2  RT @RawStory: Researchers say we have three ye...   698562   \n",
       "3           1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736   \n",
       "4           1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954   \n",
       "5           1  Worth a read whether you do or don't believe i...   425577   \n",
       "6           1  RT @thenation: Mike Pence doesn’t believe in g...   294933   \n",
       "7           1  RT @makeandmendlife: Six big things we can ALL...   992717   \n",
       "8           1  @AceofSpadesHQ My 8yo nephew is inconsolable. ...   664510   \n",
       "9           1  RT @paigetweedy: no offense… but like… how do ...   260471   \n",
       "10          1  RT @StephenSchlegel: she's thinking about how ...   295793   \n",
       "\n",
       "                                             message1  \n",
       "0   polyscimajor epa chief not think carbon dioxid...  \n",
       "1   not like we lack evidence anthropogenic global...  \n",
       "2   researcher say we three year act climate chang...  \n",
       "3   todayinmaker wired  wa pivotal year in war cli...  \n",
       "4    and racist sexist climate change denying bigo...  \n",
       "5   worth read whether you not believe in climate ...  \n",
       "6   mike penny doesn’t believe in global warming s...  \n",
       "7   six big thing we can today fight climate chang...  \n",
       "8   my yo nephew inconsolable want die old age lik...  \n",
       "9   no offense… but like… how you just not believe...  \n",
       "10  shes thinking about how shes going die because...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nlppreprocess import NLP\n",
    "nlp = NLP()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "def clean(tweet):\n",
    "    #remove mentions\n",
    "    tweet = re.sub(r'@[A-Za-z0-9]+', '', tweet) \n",
    "    \n",
    "    #remove hashtag\n",
    "    tweet = re.sub(r'#', '', tweet) \n",
    "    \n",
    "    #remove RT\n",
    "    tweet = re.sub (r'RT[\\s]+', '', tweet)\n",
    "    \n",
    "    #remove hyper link\n",
    "    tweet = re.sub(r'https?:\\/\\/\\S', '', tweet) \n",
    "    \n",
    "    #turning the tweet to lowercase \n",
    "    tweet = tweet.lower() \n",
    "    \n",
    "    #Removing the punctuations\n",
    "    tweet = ''.join([l for l in tweet if l not in string.punctuation])\n",
    "    \n",
    "    #Tokenise the tweet\n",
    "    tokeniser = TreebankWordTokenizer()\n",
    "    tweet = tokeniser.tokenize(tweet)\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tweet = ' '.join(lemmatizer.lemmatize(word) for word in tweet)   \n",
    "    \n",
    "    #remove stop words\n",
    "    stopwords = NLP(replace_words=True, remove_stopwords=True, \n",
    "                            remove_numbers=True, remove_punctuations=False) \n",
    "    tweet = stopwords.process(tweet)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "train_df['message1'] = train_df['message'].apply(clean)\n",
    "train_df.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model only recognise numeric data for predictions, the text data has to be converted to numeric data type and this is achieved using text frequency - inverse document frequency (TF-IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF for coverting text to numeric data type\n",
    "data = train_df['message1']\n",
    "\n",
    "vectorizer=TfidfVectorizer(use_idf=True, max_df=0.95)\n",
    "X_vectorized = vectorizer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arranging the data into predictor variables and label\n",
    "X = X_vectorized\n",
    "y = train_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       " 1    8530\n",
       " 2    3640\n",
       " 0    2353\n",
       "-1    1296\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "\n",
    "\n",
    "plt.title('Class Frequency')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(ticks=[-1,0,1,2], labels=[-1,0,1,2])\n",
    "plt.ylim(top=10000)\n",
    "\n",
    "plt.show()\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting the training data into test and training, or test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the training data into 80% training and 20% training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Oversampling for Handling Imbalanced \n",
    "smk = SMOTETomek()\n",
    "X_res,y_res=smk.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "model1 = LogisticRegression(C = 10,random_state = 12)\n",
    "#model = DecisionTreeClassifier(max_depth = 2)\n",
    "model1 = SVC(kernel = 'linear', C = 1)\n",
    "#model2 = KNeighborsClassifier(n_neighbors = 1)\n",
    "#model3 = MultinomialNB(1)\n",
    "\n",
    "ovr = OneVsOneClassifier(model1)\n",
    "ovr.fit(X_train, y_train)\n",
    "\n",
    "pred = ovr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7357774968394437\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.37      0.49       278\n",
      "           0       0.58      0.40      0.47       425\n",
      "           1       0.75      0.87      0.81      1755\n",
      "           2       0.77      0.74      0.75       706\n",
      "\n",
      "    accuracy                           0.74      3164\n",
      "   macro avg       0.71      0.60      0.63      3164\n",
      "weighted avg       0.73      0.74      0.72      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "#print(confusion_matrix(y_test,yhat))\n",
    "print(accuracy_score(y_test,pred))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different models will be compared in this section of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for the data we want to log \n",
    "params = {\"random_state\": 7,\n",
    "          \"model_type\": \"logreg\", \n",
    "          \"scaler\": \"standard scaler\", \n",
    "          \"param_grid\": str(accuracy_score(y_test,pred)),\n",
    "          \"stratify\": True } \n",
    "metrics = {\"f1\": accuracy_score(y_test,pred),\n",
    "           \"recall\": accuracy_score(y_test,pred),\n",
    "           \"precision\": accuracy_score(y_test,pred) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.log_parameters(params) \n",
    "experiment.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"https://www.comet.ml/phaks323/ea6/eee7854f4e98462b97fce4be0466a2fe\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x23dcd8c0f70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression for multi-class classification using a one-vs-rest\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "# define dataset\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "# define the ovr strategy\n",
    "ovr = OneVsRestClassifier(model)\n",
    "# fit model\n",
    "ovr.fit(X_train, y_train)\n",
    "# make predictions\n",
    "yhat = ovr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12655"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7164981036662452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.21      0.34       278\n",
      "           0       0.67      0.30      0.41       425\n",
      "           1       0.71      0.91      0.80      1755\n",
      "           2       0.75      0.68      0.71       706\n",
      "\n",
      "    accuracy                           0.72      3164\n",
      "   macro avg       0.75      0.53      0.57      3164\n",
      "weighted avg       0.73      0.72      0.69      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "#print(confusion_matrix(y_test,yhat))\n",
    "print(accuracy_score(y_test,yhat))\n",
    "print(classification_report(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression for multi-class classification using built-in one-vs-rest\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# define dataset\n",
    "# define model\n",
    "model1 = LogisticRegression(multi_class='ovr')\n",
    "# fit model\n",
    "model1.fit(X_train, y_train)\n",
    "# make predictions\n",
    "yhat3 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  59   29  175   15]\n",
      " [   3  128  269   25]\n",
      " [   2   33 1601  119]\n",
      " [   2    2  223  479]]\n",
      "0.7164981036662452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.21      0.34       278\n",
      "           0       0.67      0.30      0.41       425\n",
      "           1       0.71      0.91      0.80      1755\n",
      "           2       0.75      0.68      0.71       706\n",
      "\n",
      "    accuracy                           0.72      3164\n",
      "   macro avg       0.75      0.53      0.57      3164\n",
      "weighted avg       0.73      0.72      0.69      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "print(confusion_matrix(y_test,yhat3))\n",
    "print(accuracy_score(y_test,yhat3))\n",
    "print(classification_report(y_test,yhat3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SVM for multi-class classification using built-in one-vs-one\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "# define dataset\n",
    "# define model\n",
    "model2 = SVC(decision_function_shape='ovo')\n",
    "# fit model\n",
    "model2.fit(X_train, y_train)\n",
    "# make predictions\n",
    "yhat1 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  62   12  194   10]\n",
      " [   3  104  300   18]\n",
      " [   1   15 1651   88]\n",
      " [   1    1  218  486]]\n",
      "0.7278761061946902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.22      0.36       278\n",
      "           0       0.79      0.24      0.37       425\n",
      "           1       0.70      0.94      0.80      1755\n",
      "           2       0.81      0.69      0.74       706\n",
      "\n",
      "    accuracy                           0.73      3164\n",
      "   macro avg       0.80      0.52      0.57      3164\n",
      "weighted avg       0.75      0.73      0.69      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "print(confusion_matrix(y_test,yhat1))\n",
    "print(accuracy_score(y_test,yhat1))\n",
    "print(classification_report(y_test,yhat1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SVM for multi-class classification using one-vs-one\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "# define dataset\n",
    "# define model\n",
    "model3 = SVC()\n",
    "# define ovo strategy\n",
    "ovo = OneVsOneClassifier(model3)\n",
    "# fit model\n",
    "ovo.fit(X_train, y_train)\n",
    "# make predictions\n",
    "yhat2 = ovo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  61   12  195   10]\n",
      " [   3  104  301   17]\n",
      " [   1   15 1651   88]\n",
      " [   1    1  218  486]]\n",
      "0.7275600505689002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.22      0.35       278\n",
      "           0       0.79      0.24      0.37       425\n",
      "           1       0.70      0.94      0.80      1755\n",
      "           2       0.81      0.69      0.74       706\n",
      "\n",
      "    accuracy                           0.73      3164\n",
      "   macro avg       0.80      0.52      0.57      3164\n",
      "weighted avg       0.75      0.73      0.69      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "print(confusion_matrix(y_test,yhat2))\n",
    "print(accuracy_score(y_test,yhat2))\n",
    "print(classification_report(y_test,yhat2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an instance\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  72   37  156   13]\n",
      " [   6  144  248   27]\n",
      " [   5   37 1591  122]\n",
      " [   3    4  202  497]]\n",
      "0.7281921618204804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.26      0.40       278\n",
      "           0       0.65      0.34      0.45       425\n",
      "           1       0.72      0.91      0.81      1755\n",
      "           2       0.75      0.70      0.73       706\n",
      "\n",
      "    accuracy                           0.73      3164\n",
      "   macro avg       0.74      0.55      0.59      3164\n",
      "weighted avg       0.73      0.73      0.70      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the model  will be applied on the testing data (unseen) to make predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the state of the testing data. Start with checking the number of columns and raws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10546, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data types on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10546 entries, 0 to 10545\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   message  10546 non-null  object\n",
      " 1   tweetid  10546 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 164.9+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are any null/empty fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "message    0\n",
       "tweetid    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now clean the testing data in the same way the training data was cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>message1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "      <td>europe will now looking china make sure not al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "      <td>combine with polling staffer re climate change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "      <td>scary unimpeachable evidence climate change al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "      <td>putin got you too jill trump not believe in cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "      <td>female orgasm cause global warming sarcastic r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid  \\\n",
       "0  Europe will now be looking to China to make su...   169760   \n",
       "1  Combine this with the polling of staffers re c...    35326   \n",
       "2  The scary, unimpeachable evidence that climate...   224985   \n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263   \n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928   \n",
       "\n",
       "                                            message1  \n",
       "0  europe will now looking china make sure not al...  \n",
       "1  combine with polling staffer re climate change...  \n",
       "2  scary unimpeachable evidence climate change al...  \n",
       "3  putin got you too jill trump not believe in cl...  \n",
       "4  female orgasm cause global warming sarcastic r...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['message1'] = test_df['message'].apply(clean)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the cleaned data into a numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF for text to numeric\n",
    "test_data = test_df['message1']\n",
    "\n",
    "vectorized_t = vectorizer.transform(test_data)\n",
    "X_test_t = vectorized_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = ovr.predict(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10546"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tunning the predictions into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'tweetid':test_df['tweetid'],\n",
    "                          'sentiment':y_test_pred})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copying the predictions into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('classification2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above saved CSV file on Kaggle for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_save_path = \"lr2.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(lr,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
